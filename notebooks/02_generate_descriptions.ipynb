{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57f2b271",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "from tqdm.notebook import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "313f3097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load OpenAI key\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "70b39384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(\"../data/processed/120k_properties.csv\")\n",
    "\n",
    "# Keep relevant columns\n",
    "cols = [\"property_id\", \"address\", \"city\", \"state\", \"postcode\", \"price\", \"property_type\"]\n",
    "df = df[cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e659f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a prompt template\n",
    "def format_prompt(row):\n",
    "    return (\n",
    "        f\"Write a short and appealing real estate listing description under 100 words. \"\n",
    "        f\"Details: A {row['property_type']} located at {row['address']}, {row['city']}, {row['state']} {row['postcode']}. \"\n",
    "        f\"Listed for ${row['price']:,.0f}.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61f34724",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_descriptions(rows, max_retries=3):\n",
    "    prompts = [format_prompt(row) for _, row in rows.iterrows()]\n",
    "    messages = [{\"role\": \"user\", \"content\": p} for p in prompts]\n",
    "    \n",
    "    retries = 0\n",
    "    while retries < max_retries:\n",
    "        try:\n",
    "            response = openai.ChatCompletion.create(\n",
    "                model=\"gpt-3.5-turbo-instruct\",\n",
    "                messages=messages,\n",
    "                temperature=0.7,\n",
    "                max_tokens=100,\n",
    "                n=1,\n",
    "                stop=None\n",
    "            )\n",
    "            return [choice[\"message\"][\"content\"] for choice in response[\"choices\"]]\n",
    "        except Exception as e:\n",
    "            retries += 1\n",
    "            time.sleep(2 ** retries)\n",
    "            print(f\"Retry {retries}/{max_retries} after error: {e}\")\n",
    "    return [\"\"] * len(rows)  # fallback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ff425086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a89367c7dec4fdb94e606f30b9edb36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retry 1/3 after error: \n",
      "\n",
      "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
      "\n",
      "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
      "\n",
      "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
      "\n",
      "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
      "\n",
      "Retry 2/3 after error: \n",
      "\n",
      "You tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n",
      "\n",
      "You can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n",
      "\n",
      "Alternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n",
      "\n",
      "A detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAPIRemovedInV1\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mgenerate_descriptions\u001b[39m\u001b[34m(rows, max_retries)\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     response = \u001b[43mopenai\u001b[49m\u001b[43m.\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpt-3.5-turbo-instruct\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.7\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [choice[\u001b[33m\"\u001b[39m\u001b[33mmessage\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m choice \u001b[38;5;129;01min\u001b[39;00m response[\u001b[33m\"\u001b[39m\u001b[33mchoices\u001b[39m\u001b[33m\"\u001b[39m]]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/workspace/real-estate-rag/.venv/lib/python3.13/site-packages/openai/lib/_old_api.py:39\u001b[39m, in \u001b[36mAPIRemovedInV1Proxy.__call__\u001b[39m\u001b[34m(self, *_args, **_kwargs)\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *_args: Any, **_kwargs: Any) -> Any:\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m APIRemovedInV1(symbol=\u001b[38;5;28mself\u001b[39m._symbol)\n",
      "\u001b[31mAPIRemovedInV1\u001b[39m: \n\nYou tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[32m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(test_df), batch_size)):\n\u001b[32m      7\u001b[39m     batch = df.iloc[i:i + batch_size]\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     outputs = \u001b[43mgenerate_descriptions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m     descriptions.extend(outputs)\n\u001b[32m     10\u001b[39m     time.sleep(\u001b[32m0.6\u001b[39m)  \u001b[38;5;66;03m# be gentle on the rate limits\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mgenerate_descriptions\u001b[39m\u001b[34m(rows, max_retries)\u001b[39m\n\u001b[32m     17\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     18\u001b[39m         retries += \u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m         \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRetry \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mretries\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_retries\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m after error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m] * \u001b[38;5;28mlen\u001b[39m(rows)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "descriptions = []\n",
    "batch_size = 5\n",
    "\n",
    "test_df = df.sample(100)  # Test with a small sample first\n",
    "\n",
    "for i in tqdm(range(0, len(test_df), batch_size)):\n",
    "    batch = df.iloc[i:i + batch_size]\n",
    "    outputs = generate_descriptions(batch)\n",
    "    descriptions.extend(outputs)\n",
    "    time.sleep(0.6)  # be gentle on the rate limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a5f13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"generated_description\"] = descriptions\n",
    "test_df.to_csv(\"../data/processed/100_properties_with_descriptions_test.csv\", index=False)\n",
    "print(\"✅ Descriptions saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
